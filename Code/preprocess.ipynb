{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load Data with Dask and optimize memory usage\n",
    "data = dd.read_parquet('sequence_features_val.parquet')\n",
    "\n",
    "# Drop 'ID' column if present and optimize data types\n",
    "data = data.drop(columns=['ID'], errors='ignore').astype('float32')\n",
    "data = data.compute()  # Convert to a Pandas DataFrame\n",
    "\n",
    "# Assign labels directly\n",
    "num_positive_samples = 1249857\n",
    "labels = pd.Series([1] * num_positive_samples + [0] * (len(data) - num_positive_samples), name='label')\n",
    "\n",
    "# Separate features and labels\n",
    "features = data\n",
    "assert len(features) == len(labels), \"Mismatch between features and labels!\"\n",
    "\n",
    "features = features.fillna(0)\n",
    "\n",
    "\n",
    "# Split into train and test sets with stratification to maintain class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    labels, \n",
    "    test_size=0.3, \n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=labels  # Ensures both train and test have proportional classes\n",
    ")\n",
    "\n",
    "# Function for training and evaluating models\n",
    "def train_and_evaluate(model, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    precision = precision_score(y_test, preds, average='weighted')\n",
    "    recall = recall_score(y_test, preds, average='weighted')\n",
    "    f1 = f1_score(y_test, preds, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'Predictions': preds,\n",
    "        'Trained_Model': model\n",
    "    }\n",
    "\n",
    "# Define models\n",
    "models = [\n",
    "    (RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42), 'Random Forest'),\n",
    "    (XGBClassifier(n_estimators=100, tree_method='hist', random_state=42), 'XGBoost'),\n",
    "    (MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42), 'Neural Network')\n",
    "]\n",
    "\n",
    "# Train models in parallel\n",
    "results = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(train_and_evaluate, model, name) for model, name in models]\n",
    "    for future in futures:\n",
    "        results.append(future.result())\n",
    "\n",
    "# Compile results into a DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': [result['Model'] for result in results],\n",
    "    'Accuracy': [result['Accuracy'] for result in results],\n",
    "    'Precision': [result['Precision'] for result in results],\n",
    "    'Recall': [result['Recall'] for result in results],\n",
    "    'F1-Score': [result['F1-Score'] for result in results]\n",
    "})\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('Final_results_ML_DL.csv', index=False)\n",
    "\n",
    "# Save feature importances for Random Forest model\n",
    "rf_importance_df = pd.DataFrame({\n",
    "    'Feature': features.columns,\n",
    "    'Importance': results[0]['Trained_Model'].feature_importances_  # Assuming Random Forest is the first model\n",
    "})\n",
    "rf_importance_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "rf_importance_df.to_csv('feature_importances_ML_DL.csv', index=False)\n",
    "\n",
    "# Save models\n",
    "for result in results:\n",
    "    joblib.dump(result['Trained_Model'], f\"{result['Model'].replace(' ', '_').lower()}_model.joblib\")\n",
    "\n",
    "print(\"Models trained in parallel, results saved, and models serialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dask_ml.model_selection import train_test_split as dask_train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# Step 1: Load the Data\n",
    "parquet_file = 'sequence_features_val.parquet'\n",
    "# parquet_file = 'sampled_Data.parquet'\n",
    "data = dd.read_parquet(parquet_file)\n",
    "\n",
    "# Load labels\n",
    "labels_df = pd.read_csv('labels_Val.csv')\n",
    "# labels_df = pd.read_csv('sample_Data_labels_val.csv')\n",
    "\n",
    "\n",
    "data = data.drop(columns=['ID'], errors='ignore')  # Drop 'ID' column if still present\n",
    "\n",
    "# Merge on index\n",
    "\n",
    "data = data.join(labels_df, how='inner')  # Inner join on the index\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "features = data.drop('label', axis=1)\n",
    "labels = data['label']\n",
    "\n",
    "\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = dask_train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "with joblib.parallel_backend('threading'):\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "    rf_model.fit(X_train.compute(), y_train.compute())  # Compute to fit with Scikit-Learn\n",
    "    importance_df = pd.DataFrame({'Feature': features.columns, 'Importance': rf_model.feature_importances_})\n",
    "\n",
    "    # Step 2: Train XGBoost Classifier\n",
    "    xgb_model = XGBClassifier(n_estimators=100, tree_method='hist', random_state=42)  # GPU: 'gpu_hist' for faster training\n",
    "    xgb_model.fit(X_train.compute(), y_train.compute())  # Compute to fit with XGBoost\n",
    "\n",
    "    # Step 3: Train Neural Network Classifier\n",
    "    nn_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "    nn_model.fit(X_train.compute(), y_train.compute())  # Compute to fit with Neural Network\n",
    "\n",
    "# Step 4: Evaluate Models\n",
    "rf_preds = rf_model.predict(X_test.compute())\n",
    "xgb_preds = xgb_model.predict(X_test.compute())\n",
    "nn_preds = nn_model.predict(X_test.compute())\n",
    "\n",
    "# Calculate metrics\n",
    "rf_accuracy = accuracy_score(y_test.compute(), rf_preds)\n",
    "xgb_accuracy = accuracy_score(y_test.compute(), xgb_preds)\n",
    "nn_accuracy = accuracy_score(y_test.compute(), nn_preds)\n",
    "\n",
    "# Prepare results DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'XGBoost', 'Neural Network'],\n",
    "    'Accuracy': [rf_accuracy, xgb_accuracy, nn_accuracy],\n",
    "    'Precision': [\n",
    "        precision_score(y_test.compute(), rf_preds, average='weighted'),\n",
    "        precision_score(y_test.compute(), xgb_preds, average='weighted'),\n",
    "        precision_score(y_test.compute(), nn_preds, average='weighted')\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_score(y_test.compute(), rf_preds, average='weighted'),\n",
    "        recall_score(y_test.compute(), xgb_preds, average='weighted'),\n",
    "        recall_score(y_test.compute(), nn_preds, average='weighted')\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        f1_score(y_test.compute(), rf_preds, average='weighted'),\n",
    "        f1_score(y_test.compute(), xgb_preds, average='weighted'),\n",
    "        f1_score(y_test.compute(), nn_preds, average='weighted')\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv('Final_results_ML_DL.csv', index=False)\n",
    "\n",
    "# Step 5: Save Classification Reports\n",
    "rf_classification_report = classification_report(y_test.compute(), rf_preds, output_dict=True)\n",
    "xgb_classification_report = classification_report(y_test.compute(), xgb_preds, output_dict=True)\n",
    "nn_classification_report = classification_report(y_test.compute(), nn_preds, output_dict=True)\n",
    "\n",
    "# Convert classification reports to DataFrame and save\n",
    "classification_reports_df = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'XGBoost', 'Neural Network'],\n",
    "    'Classification Report': [\n",
    "        rf_classification_report,\n",
    "        xgb_classification_report,\n",
    "        nn_classification_report\n",
    "    ]\n",
    "})\n",
    "\n",
    "classification_reports_df.to_csv('classification_result_ML_DL.csv', index=False)\n",
    "\n",
    "\n",
    "# Classification Reports\n",
    "print(\"\\nRandom Forest Classification Report:\")\n",
    "print(rf_classification_report)\n",
    "\n",
    "print(\"\\nXGBoost Classification Report:\")\n",
    "print(xgb_classification_report)\n",
    "\n",
    "# Classification Reports\n",
    "print(\"\\nNN Classification Report:\")\n",
    "print(nn_classification_report)\n",
    "\n",
    "# Save feature importances to CSV\n",
    "importance_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "importance_df.to_csv('feature_importances_ML_DL.csv', index=False)\n",
    "\n",
    "# Step 6: Save the trained models\n",
    "joblib.dump(rf_model, 'rf_model.joblib')\n",
    "joblib.dump(xgb_model, 'xgb_model.joblib')\n",
    "joblib.dump(nn_model, 'nn_model.joblib')\n",
    "\n",
    "print(\"Models trained, results saved, and models serialized.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
